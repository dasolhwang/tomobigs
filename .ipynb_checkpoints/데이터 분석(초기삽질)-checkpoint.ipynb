{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'cp949' codec can't decode byte 0x80 in position 2: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-7f56f53ecac9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score1694.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cp949\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Unnamed: 0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#del df[\"Unnamed: 0.1\"]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'cp949' codec can't decode byte 0x80 in position 2: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"score1694.csv\", encoding=\"cp949\")\n",
    "del df[\"Unnamed: 0\"]\n",
    "#del df[\"Unnamed: 0.1\"]\n",
    "#del df[\"Unnamed: 0.1.1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0.1', '글쎄요', '보고싶어요', '참여인원', '평점', 'title', 'y', '런타임',\n",
       "       '장르', '개봉일', '등급', '개봉년도', '개봉월'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## object 변수 따로 빼기(df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats =[]\n",
    "for col in df.columns.values:\n",
    "    if df[col].dtype == 'object':\n",
    "        cats.append(col)\n",
    "        \n",
    "df_cont = df.drop(cats, axis=1)\n",
    "df_cont = df.drop(\"y\", axis=1)\n",
    "y = df[\"y\"]\n",
    "df_cat = df[cats]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## object변수 더미화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "등급\n",
      "개봉년도\n",
      "개봉월\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "for col in df_cat.columns.values:\n",
    "    print(col)\n",
    "    df_cat[col] = LabelEncoder().fit_transform(df_cat[col])\n",
    "    num_cols = df_cat[col].max()\n",
    "    \n",
    "    for i in range(num_cols):\n",
    "        col_name = col + '_' + str(i)\n",
    "        df_cat[col_name] = df_cat[col].apply(lambda x: 1 if x == i else 0)\n",
    "    \n",
    "    df_cat = df_cat.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 아웃라이어 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_outlier(points, thresh=3.5):\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:,None]\n",
    "    median = np.median(points, axis=0)\n",
    "    diff = np.sum((points - median)**2, axis=-1)\n",
    "    diff = np.sqrt(diff)\n",
    "    med_abs_deviation = np.median(diff)\n",
    "\n",
    "    modified_z_score = 0.6745 * diff / med_abs_deviation\n",
    "\n",
    "    return modified_z_score > thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수치형 변수 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "for col in df_cont.columns.values:\n",
    "    if sum(df_cont[col]==0) > 0:\n",
    "        median = df_cont[col].median()\n",
    "        idx = np.where(df_cont[col]==0)[0]\n",
    "        df_cont[col].iloc[idx] = median\n",
    "        \n",
    "        outliers = np.where(is_outlier(df_cont[col]))\n",
    "        df_cont[col].iloc[outliers] = median\n",
    "        \n",
    "        if skew(df_cont[col]) > 0.75:\n",
    "            df_cont[col] = np.log(df_cont[col])\n",
    "            df_cont[col] = df_cont[col].apply(lambda x: 0 if x == -np.inf else x)\n",
    "        \n",
    "        df_cont[col] = Normalizer().fit_transform(df_cont[col].reshape(1,-1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_cont.join(df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop([\"등급\",\"개봉년도\",\"개봉월\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "train_X, test_X = train_test_split(df_new, test_size = 0.3, random_state=1) # 독립변수만\n",
    "train_Y, test_Y = train_test_split(y, test_size = 0.3, random_state=1) # 종속변수만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(train_X)\n",
    "train_X_std = sc.transform(train_X)\n",
    "test_X_std = sc.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 간단한 모델들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.588235294118\n",
      "0.558823529412\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "ml = LogisticRegression()\n",
    "ml.fit(train_X_std, train_Y)\n",
    "pred = ml.predict(test_X_std)\n",
    "print(accuracy_score(test_Y, pred)) \n",
    "\n",
    "ml2 = LogisticRegression()\n",
    "ml2.fit(train_X, train_Y)\n",
    "pred2 = ml2.predict(test_X)\n",
    "print(accuracy_score(test_Y, pred2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [ 0.625       0.5         0.875       0.625       0.5         0.5         0.5\n",
      "  0.57142857  0.57142857  0.71428571]\n",
      "CV accuracy: 0.598 +/- 0.115\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "tree = tree.DecisionTreeClassifier(criterion='entropy', max_depth=4, random_state=0)\n",
    "tree.fit(train_X_std, train_Y)\n",
    "\n",
    "pred_tr = tree.predict(test_X_std)\n",
    "#print('Accuracy: %.2f' % accuracy_score(test_Y, pred_tr))\n",
    "scores = cross_val_score(estimator=tree,X=train_X, y=train_Y, cv=10,n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [ 0.5         0.5         0.5         0.5         0.5         0.5         0.5\n",
      "  0.57142857  0.57142857  0.57142857]\n",
      "CV accuracy: 0.521 +/- 0.033\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc1 = SVC(kernel=\"rbf\",gamma=0.01, random_state=0)\n",
    "svc1.fit(train_X_std, train_Y)\n",
    "pred_svc1 = svc1.predict(test_X_std)\n",
    "#print('Accuracy: %.2f' % accuracy_score(test_Y, pred_svc1))\n",
    "scores = cross_val_score(estimator=svc1,X=train_X, y=train_Y, cv=10,n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n",
      "CV accuracy scores: [ 0.625       0.5         0.75        0.5         0.75        0.625       0.75\n",
      "  0.71428571  0.85714286  0.71428571]\n",
      "CV accuracy: 0.679 +/- 0.109\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn1 = KNeighborsClassifier(n_neighbors=7, p=2, metric='minkowski' )\n",
    "knn1.fit(train_X, train_Y)\n",
    "pred_knn1 = knn1.predict(test_X)\n",
    "print('Accuracy: %.2f' % accuracy_score(test_Y, pred_knn1))\n",
    "scores = cross_val_score(estimator=knn1,X=train_X, y=train_Y, cv=10,n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' `% (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [ 0.625       0.375       0.625       0.625       0.75        0.75        0.625\n",
      "  0.57142857  0.85714286  0.71428571]\n",
      "CV accuracy: 0.652 +/- 0.123\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf1 = RandomForestClassifier(criterion=\"entropy\", n_estimators = 100, n_jobs=2, random_state=0)\n",
    "rf1.fit(train_X_std, train_Y)\n",
    "pred_rf1 = rf1.predict(test_X_std) \n",
    "#print('Accuracy: %.2f' % accuracy_score(test_Y, pred_rf1))\n",
    "scores = cross_val_score(estimator=rf1,X=train_X, y=train_Y, cv=10,n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "scorer = make_scorer(mean_squared_error, False)\n",
    "\n",
    "RF = RandomForestClassifier(n_estimators=500, n_jobs=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [ 0.625       0.375       0.75        0.5         0.75        0.75        0.625\n",
      "  0.57142857  0.85714286  0.71428571]\n",
      "CV accuracy: 0.652 +/- 0.135\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "scores = cross_val_score(estimator=RF, \n",
    "                         X=train_X, \n",
    "                         y=train_Y, \n",
    "                         cv=10,\n",
    "                         n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "보고싶어요        0.123435\n",
       "기대지수         0.119875\n",
       "관심인원         0.089849\n",
       "글쎄요          0.083259\n",
       "런타임          0.077495\n",
       "참여인원         0.076977\n",
       "id_length    0.070460\n",
       "평점           0.065753\n",
       "배우수          0.062916\n",
       "조연수          0.055116\n",
       "주연수          0.026210\n",
       "개봉년도_0       0.017727\n",
       "개봉월_3        0.012967\n",
       "등급_0         0.012371\n",
       "등급_1         0.012049\n",
       "개봉년도_2       0.010577\n",
       "개봉년도_1       0.009940\n",
       "개봉월_2        0.009717\n",
       "개봉월_4        0.009205\n",
       "개봉월_5        0.009167\n",
       "개봉월_8        0.008696\n",
       "개봉월_1        0.007935\n",
       "개봉월_7        0.007173\n",
       "개봉월_10       0.005301\n",
       "개봉월_0        0.005232\n",
       "개봉월_6        0.004288\n",
       "개봉월_9        0.003679\n",
       "등급_2         0.002630\n",
       "미스터리         0.000000\n",
       "판타지          0.000000\n",
       "코미디          0.000000\n",
       "전쟁           0.000000\n",
       "액션           0.000000\n",
       "스릴러          0.000000\n",
       "서스펜스         0.000000\n",
       "범죄           0.000000\n",
       "SF           0.000000\n",
       "가족           0.000000\n",
       "공포           0.000000\n",
       "느와르          0.000000\n",
       "다큐멘터리        0.000000\n",
       "드라마          0.000000\n",
       "로맨스          0.000000\n",
       "멜로           0.000000\n",
       "모험           0.000000\n",
       "서사           0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF.fit(train_X, train_Y)\n",
    "pred_RF = RF.predict(test_X)\n",
    "print('Accuracy: %.2f' % accuracy_score(test_Y, pred_RF))\n",
    "coef = pd.Series(RF.feature_importances_, index = train_X.columns).sort_values(ascending=False)\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y            1.000000e+00\n",
      "기대지수         3.323805e-01\n",
      "개봉년도_0       2.688474e-01\n",
      "런타임          2.387938e-01\n",
      "배우수          2.320634e-01\n",
      "보고싶어요        2.259708e-01\n",
      "등급_0         2.057911e-01\n",
      "조연수          2.022429e-01\n",
      "관심인원         1.696675e-01\n",
      "개봉월_8        1.479591e-01\n",
      "평점           1.470488e-01\n",
      "개봉월_5        1.262571e-01\n",
      "개봉년도_2       1.106368e-01\n",
      "개봉월_6        1.083086e-01\n",
      "주연수          1.054438e-01\n",
      "참여인원         8.312255e-02\n",
      "개봉월_9        7.501724e-02\n",
      "개봉월_10       6.301961e-02\n",
      "개봉월_7        5.463825e-02\n",
      "개봉월_1        1.133462e-02\n",
      "드라마         -5.627480e-17\n",
      "개봉월_4       -3.287980e-02\n",
      "등급_2        -5.931596e-02\n",
      "개봉월_0       -8.563933e-02\n",
      "등급_1        -8.701726e-02\n",
      "개봉년도_1      -1.284169e-01\n",
      "글쎄요         -1.436867e-01\n",
      "개봉월_2       -1.880817e-01\n",
      "개봉월_3       -2.169130e-01\n",
      "id_length   -3.242383e-01\n",
      "SF                    NaN\n",
      "가족                    NaN\n",
      "공포                    NaN\n",
      "느와르                   NaN\n",
      "다큐멘터리                 NaN\n",
      "로맨스                   NaN\n",
      "멜로                    NaN\n",
      "모험                    NaN\n",
      "미스터리                  NaN\n",
      "범죄                    NaN\n",
      "서사                    NaN\n",
      "서스펜스                  NaN\n",
      "스릴러                   NaN\n",
      "액션                    NaN\n",
      "전쟁                    NaN\n",
      "코미디                   NaN\n",
      "판타지                   NaN\n",
      "Name: y, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "X = train_X\n",
    "X[\"y\"] = y\n",
    "# 종속변수과 상관관계 높은 변수 보기\n",
    "corr = X.corr()\n",
    "corr.sort_values([\"y\"], ascending=False, inplace=True)\n",
    "print(corr.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 상위 몇개 변수에 3승 까지 적용\n",
    "df_new[\"기대지수-s2\"] = df_new[\"기대지수\"] **2\n",
    "df_new[\"기대지수-s3\"] = df_new[\"기대지수\"] **3\n",
    "df_new[\"기대지수-sq\"] = np.sqrt(df_new[\"기대지수\"])\n",
    "\n",
    "df_new[\"런타임-s2\"] = df_new[\"런타임\"] **2\n",
    "df_new[\"런타임-s3\"] = df_new[\"런타임\"] **3\n",
    "df_new[\"런타임-sq\"] = np.sqrt(df_new[\"런타임\"])\n",
    "\n",
    "df_new[\"id-s2\"] = df_new[\"id_length\"] **2\n",
    "df_new[\"id-s3\"] = df_new[\"id_length\"] **3\n",
    "df_new[\"id-sq\"] = np.sqrt(df_new[\"id_length\"])\n",
    "\n",
    "df_new[\"보고싶어요-s2\"] = df_new[\"보고싶어요\"] **2\n",
    "df_new[\"보고싶어요-s3\"] = df_new[\"보고싶어요\"] **3\n",
    "df_new[\"보고싶어요-sq\"] = np.sqrt(df_new[\"보고싶어요\"])\n",
    "\n",
    "df_new[\"관심-s2\"] = df_new[\"관심인원\"] **2\n",
    "df_new[\"관심-s3\"] = df_new[\"관심인원\"] **3\n",
    "df_new[\"관심-sq\"] = np.sqrt(df_new[\"관심인원\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "train_X, test_X = train_test_split(df_new, test_size = 0.3, random_state=1) # 독립변수만\n",
    "train_Y, test_Y = train_test_split(y, test_size = 0.3, random_state=1) # 종속변수만"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(train_X)\n",
    "train_X_std = sc.transform(train_X)\n",
    "test_X_std = sc.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha :  60.0\n",
      "Best alpha :  84.0\n",
      "ridge는 변수를 몇개 선택했니? :  44\n",
      "ridge는 변수를 몇개 버렸니? :  17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV, ElasticNetCV\n",
    "\n",
    "ridge = RidgeCV(alphas = [0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3 , 6, 10, 30,60])\n",
    "ridge.fit(train_X, train_Y)\n",
    "alpha = ridge.alpha_\n",
    "print(\"Best alpha : \", alpha)\n",
    "\n",
    "ridge = RidgeCV(alphas = [alpha *.6, alpha * .65, alpha * .7,alpha * .75,\n",
    "                         alpha * .8, alpha * .85, alpha * .9, alpha * .95,\n",
    "                         alpha * 1.05, alpha * 1.1, alpha * 1.15, alpha * 1.25,\n",
    "                         alpha * 1.3, alpha * 1.35, alpha * 1.4], cv=10)\n",
    "ridge.fit(train_X, train_Y)\n",
    "alpha = ridge.alpha_\n",
    "print(\"Best alpha : \", alpha)\n",
    "pred_ridge = ridge.predict(test_X)\n",
    "#print('Accuracy: %.2f' % accuracy_score(test_Y, pred_lasso))\n",
    "\n",
    "coefs = pd.Series(ridge.coef_, index = train_X.columns)\n",
    "print(\"ridge는 변수를 몇개 선택했니? : \", sum(coefs!=0)) \n",
    "print(\"ridge는 변수를 몇개 버렸니? : \", sum(coefs==0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha :  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha :  1.4\n",
      "lasso는 변수를 몇개 선택했니? :  10\n",
      "lasso는 변수를 몇개 버렸니? :  51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lasso = LassoCV(alphas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, \n",
    "                          0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1])\n",
    "lasso.fit(train_X, train_Y)\n",
    "alpha = lasso.alpha_\n",
    "print(\"Best alpha : \", alpha)\n",
    "\n",
    "lasso = LassoCV(alphas = [alpha *.6, alpha * .65, alpha * .7,alpha * .75,\n",
    "                         alpha * .8, alpha * .85, alpha * .9, alpha * .95,\n",
    "                         alpha * 1.05, alpha * 1.1, alpha * 1.15, alpha * 1.25,\n",
    "                         alpha * 1.3, alpha * 1.35, alpha * 1.4],\n",
    "               max_iter = 50000, cv=10)\n",
    "lasso.fit(train_X, train_Y)\n",
    "alpha = lasso.alpha_\n",
    "print(\"Best alpha : \", alpha)\n",
    "pred_lasso = lasso.predict(test_X)\n",
    "#print('Accuracy: %.2f' % accuracy_score(test_Y, pred_lasso))\n",
    "\n",
    "coefs = pd.Series(lasso.coef_, index = train_X.columns)\n",
    "print(\"lasso는 변수를 몇개 선택했니? : \", sum(coefs!=0)) \n",
    "print(\"lasso는 변수를 몇개 버렸니? : \",sum(coefs==0)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.76\n"
     ]
    }
   ],
   "source": [
    "pred_lasso1 = np.where(pred_lasso > 0.5,1,0)\n",
    "print('Accuracy: %.2f' % accuracy_score(test_Y, pred_lasso1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "pred_ridge1 = np.where(pred_ridge > 0.5, 1, 0)\n",
    "print('Accuracy: %.2f' % accuracy_score(test_Y, pred_ridge1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.cross_validation import ShuffleSplit\n",
    "#from sklearn.utils import shuffle\n",
    "#import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy scores: [  3.55106022e-01   2.94013632e-01   2.13601675e-01  -6.40026469e-01\n",
      "  -2.70614646e+00   1.76332324e-01   7.28378575e-01  -4.44886375e-02\n",
      "   2.94735517e-01  -3.61667194e+02]\n",
      "CV accuracy: -36.300 +/- 108.460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(estimator=lasso,X=train_X, y=train_Y, cv=10,n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_val_score(estimator=ridge,X=train_X, y=train_Y, cv=10,n_jobs=1)\n",
    "print('CV accuracy scores: %s' % scores)\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
