{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, scale\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import*\n",
    "from imblearn.combine import SMOTEENN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = pd.read_csv(\"score.csv\", encoding=\"cp949\")\n",
    "\n",
    "score_count = pd.read_csv(\"score_count.csv\", encoding=\"cp949\")\n",
    "score_count_stop = pd.read_csv(\"score_count_stop.csv\", encoding=\"cp949\")\n",
    "\n",
    "score_tfidf = pd.read_csv(\"js_w2v_tfidf.csv\", encoding=\"cp949\")\n",
    "score_tfidf_stop = pd.read_csv(\"jaeseok_w2v_tfidf_stopwords.csv\", encoding=\"cp949\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del score[\"Unnamed: 0\"]\n",
    "del score_count[\"Unnamed: 0\"]\n",
    "del score_count[\"title\"]\n",
    "del score_count_stop[\"Unnamed: 0\"]\n",
    "del score_count_stop[\"title\"]\n",
    "del score_tfidf[\"Unnamed: 0\"]\n",
    "del score_tfidf[\"title\"]\n",
    "del score_tfidf_stop[\"Unnamed: 0\"]\n",
    "del score_tfidf_stop[\"title\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Modeling1(score):\n",
    "    \n",
    "    X = score.drop(\"y\", axis=1)\n",
    "    y = score[\"y\"]\n",
    "    \n",
    "    # train / test 나누기\n",
    "    X_train, X_test = train_test_split(X, test_size=0.2, random_state=0)\n",
    "    Y_train, Y_test = train_test_split(y, test_size=0.2, random_state=0)\n",
    "    \n",
    "    # 파라미터\n",
    "    param =[{\"n_neighbors\": [2,3,4,5,6], 'p':[1,2,3], \"weights\":[\"uniform\",\"distance\"]},\n",
    "            {\"C\": [0.01, 0.03, 0.1, 0.2, 0.3, 0.4, 0.6, 1, 3]},\n",
    "            {\"C\": [0.01, 0.03, 0.1, 0.3, 1, 3, 6, 9 ]},\n",
    "            {\"criterion\": ['gini','entropy'], 'max_depth':[4,5,6,7,8,9,10]},\n",
    "            {\"max_depth\": [12,13,14,15,16],\"min_samples_split\" :[4,5,6,7,8],\"min_samples_leaf\": [3,4,5,6,7],\n",
    "             \"max_features\": (5,6,7,\"sqrt\"),\"criterion\": ('gini','entropy')}]\n",
    "\n",
    "    # 모델\n",
    "    clfs = [KNeighborsClassifier(),\n",
    "            LogisticRegression(penalty='l2',class_weight='balanced', random_state=0),\n",
    "            LogisticRegression(penalty='l1',class_weight='balanced', random_state=0),\n",
    "            DecisionTreeClassifier(random_state=0,criterion='entropy'),\n",
    "            RandomForestClassifier(random_state=0, class_weight=\"balanced\")]\n",
    "\n",
    "    clfName = {1:'LO', 2:'SV', 3:'L1',4:'DT', 5:'RF'}\n",
    "\n",
    "    parameters=[]\n",
    "    val_score=[]\n",
    "    f1_test= []\n",
    "    acc_test=[]\n",
    "    \n",
    "    # CV = 10 (train 데이터 내에서 train/val 나눠서 CV)\n",
    "    for i in range(1):\n",
    "        clfs[i].fit(X_train, Y_train)\n",
    "        model = GridSearchCV(clfs[i], n_jobs=5, cv=10, scoring = 'f1') #accuracy도\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        parameters.append(model.best_params_)\n",
    "        val_score.append(model.best_score_\n",
    "\n",
    "        # cv = 10 한 모델에 test \n",
    "        pred = model.predict(X_test)\n",
    "        print (\"finish :\",clfName[i+1])\n",
    "        print(classification_report(Y_test, pred))\n",
    "        f1_test.append(classification_report(Y_test, pred))\n",
    "        acc_test.append(sum(pred==Y_test)/len(Y_test))\n",
    "        \n",
    "    return parameters, val_score, f1_test, acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param, score_train_scores, st,sa= Modeling1(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_count_param, score_count_train_scores, sst, ssa = Modeling1(score_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_count_stop_param, score_count_stop_train_scores, ssst, sssa = Modeling1(score_count_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_tfidf_param, score_tfidf_train_scores, sssst,ssssa= Modeling1(score_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_tfidf_stop_param, score_tfidf_stop_train_scores,ssssst,sssssa= Modeling1(score_tfidf_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 모델 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Modeling2(score):\n",
    "        \n",
    "    train, test = train_test_split(score, test_size=0.2, random_state=0)\n",
    "\n",
    "    X_test = test.drop(\"y\",axis=1)\n",
    "    Y_test = test[\"y\"]\n",
    "\n",
    "    # 업샘플링\n",
    "    df_majority = train[train.y==0]\n",
    "    df_minority = train[train.y==1]\n",
    "    # Upsample minority class\n",
    "    df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority),random_state=0) \n",
    "    # Combine majority class with upsampled minority class\n",
    "    train = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "    X_train = train.drop(\"y\",axis=1)\n",
    "    Y_train = train[\"y\"]\n",
    "    \n",
    "    # 파라미터\n",
    "    param =[{\"n_neighbors\": [2,3,4,5,6], 'p':[1,2,3], \"weights\":[\"uniform\",\"distance\"]},\n",
    "            {\"C\": [0.01, 0.03, 0.1, 0.2, 0.3, 0.4, 0.6, 1, 3]},\n",
    "            {\"C\": [0.01, 0.03, 0.1, 0.3, 1, 3, 6, 9 ]},\n",
    "            {\"criterion\": ['gini','entropy'], 'max_depth':[4,5,6,7,8,9,10]},\n",
    "            {\"max_depth\": [12,13,14,15,16],\"min_samples_split\" :[4,5,6,7,8],\"min_samples_leaf\": [3,4,5,6,7],\n",
    "             \"max_features\": (5,6,7,\"sqrt\"),\"criterion\": ('gini','entropy')}]\n",
    "\n",
    "    # 모델\n",
    "    clfs = [KNeighborsClassifier(), \n",
    "            LogisticRegression(penalty='l2',class_weight='balanced', random_state=0),\n",
    "            LogisticRegression(penalty='l1',class_weight='balanced', random_state=0),\n",
    "            DecisionTreeClassifier(random_state=0,criterion='entropy'),\n",
    "            RandomForestClassifier(random_state=0, class_weight=\"balanced\")]\n",
    "\n",
    "    clfName = {1:'KNN', 2:'L2', 3:'L1',4:'DT', 5:'RF'}\n",
    "\n",
    "    parameters=[]\n",
    "    scores=[]\n",
    "    f1= []\n",
    "    \n",
    "    # CV = 10\n",
    "    for i in range(len(clfs)):\n",
    "        clfs[i].fit(X_train, Y_train)\n",
    "        model = GridSearchCV(clfs[i], param[i], n_jobs=5, cv=10, scoring = 'f1')\n",
    "        model.fit(X_train, Y_train)\n",
    "\n",
    "        parameters.append(model.best_params_)\n",
    "        scores.append(model.best_score_)\n",
    "\n",
    "        # cv = 10 한 모델에 test \n",
    "        pred = model.predict(X_test)\n",
    "        print (\"finish :\",clfName[i+1])\n",
    "        print(classification_report(Y_test, pred))\n",
    "        f1.append(classification_report(Y_test, pred))\n",
    "        \n",
    "    return parameters, scores, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param, score_train_scores, st,sa= Modeling2(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_count_param, score_count_train_scores, sst, ssa = Modeling2(score_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_count_stop_param, score_count_stop_train_scores, ssst, sssa = Modeling2(score_count_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_tfidf_param, score_tfidf_train_scores, sssst,ssssa= Modeling2(score_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_tfidf_stop_param, score_tfidf_stop_train_scores,ssssst,sssssa= Modeling2(score_tfidf_stop)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
